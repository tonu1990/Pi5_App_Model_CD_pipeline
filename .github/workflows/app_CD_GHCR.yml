name: App CD • deploy Image from GHCR on Pi

on:
  # Manual trigger: choose which image tag to deploy
  workflow_dispatch:
    inputs:
      image_tag:
        description: "Image tag to deploy (e.g., v0.1.0 or latest)."
        required: false
        default: "latest"

jobs:
  deploy:
    # Run on your Pi's app runner
    runs-on: [self-hosted, pi5,app_model_cd]
    permissions:
      contents: read
      packages: read   # allows pulling private GHCR images with GITHUB_TOKEN

    env:
      # GHCR image name from Step 7
      IMAGE_NAME: ghcr.io/${{ github.repository_owner }}/pcb-app
      CONTAINER_NAME: pcb-app
      HOST_PORT: "8080"     # host port (Pi)
      CONTAINER_PORT: "8080" # container port (your FastAPI app)

    steps:
      - name: Show Docker & disk info (sanity)
        run: |
          docker version
          df -h /

      # If your package is private, the Pi must authenticate to GHCR.
      # Using the workflow's GITHUB_TOKEN works because this job runs in the same repo.
      - name: Login to GHCR
        uses: docker/login-action@v3
        with:
          registry: ghcr.io
          username: ${{ github.actor }}
          password: ${{ secrets.GITHUB_TOKEN }}

      - name: Determine image ref
        id: ref
        run: |
          TAG="${{ github.event.inputs.image_tag }}"
          if [ -z "$TAG" ]; then TAG="latest"; fi
          echo "ref=${{ env.IMAGE_NAME }}:${TAG}" >> $GITHUB_OUTPUT
          echo "Deploying image: ${{ env.IMAGE_NAME }}:${TAG}"

      - name: Pull image
        run: docker pull "${{ steps.ref.outputs.ref }}"

      - name: Ensure /opt/edge/app.env exists
        run: |
          if [ ! -f /opt/edge/app.env ]; then
            echo "Missing /opt/edge/app.env. Create it on the Pi before deploying."; exit 1
          fi
          echo "Using /opt/edge/app.env:"
          sed 's/^/  /' /opt/edge/app.env

      - name: Verify model mount directory exists
        run: |
          test -d /opt/edge/models || { echo "Missing /opt/edge/models"; exit 1; }
          ls -l /opt/edge/models || true
          readlink -f /opt/edge/models/current.onnx || echo "Note: current.onnx not set yet"

      - name: Stop & remove old container (if present)
        run: |
          docker stop ${{ env.CONTAINER_NAME }} 2>/dev/null || true
          docker rm   ${{ env.CONTAINER_NAME }} 2>/dev/null || true

      - name: Run real app container (RO model mount + env-file)
        run: |
          docker run -d --name ${{ env.CONTAINER_NAME }} \
            -p ${{ env.HOST_PORT }}:${{ env.CONTAINER_PORT }} \
            --env-file /opt/edge/app.env \
            -v /opt/edge/models:/opt/edge/models:ro \
            --restart unless-stopped \
            "${{ steps.ref.outputs.ref }}"

      # Readiness probe: the app should open the ONNX session or at least be able to list IO tensors.
      # If you haven't deployed a model yet, /readyz may be 503 until Model CD flips current.onnx.
      - name: Wait for /readyz (30s timeout)
        run: |
          for i in $(seq 1 30); do
            if curl -fsS http://localhost:${{ env.HOST_PORT }}/readyz >/dev/null; then
              echo "App is ready"; exit 0
            fi
            echo "Waiting for /readyz... ($i)"
            sleep 1
          done
          echo "Readiness failed"
          echo "--- container logs (tail) ---"
          docker logs --tail=200 ${{ env.CONTAINER_NAME }} || true
          exit 1

      # Optional but useful: prove the model mount is read-only from inside the container.
      - name: Enforce RO mount (attempt write should fail)
        run: |
          if docker exec ${{ env.CONTAINER_NAME }} sh -lc 'touch /opt/edge/models/.should_fail'; then
            echo "❌ /opt/edge/models is not read-only inside the container"; exit 1
          else
            echo "✅ Read-only model mount confirmed"
          fi

      - name: Show /info snapshot (diagnostics)
        run: |
          curl -fsS http://localhost:${{ env.HOST_PORT }}/info || true